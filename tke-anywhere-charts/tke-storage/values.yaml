global:
  enableNFS: false
  enableCephFS: false
  enableHostpathProvisioner: true

hostpath-provisioner:
  strategyType: Recreate

  image:
    repository: ccr.ccs.tencentyun.com/tdccimages/hostpath-provisioner
    # Note that by default we use appVersion to get image tag
    # tag:
    pullPolicy: IfNotPresent

  ## For creating the StorageClass automatically:
  storageClass:
    create: true

    ## Set StorageClass as the default StorageClass
    ## Ignored if storageClass.create is false
    defaultClass: true

    ## Set a StorageClass name
    name: anywhere-sc

  ## Set the provisioner name
  provisionerName: hostpath

  ## Set the reclaimPolicy
  reclaimPolicy: Retain

  ## Set the local HostPath to be used on the node
  nodeHostPath: /var/lib/tke-anywhere

  ## Node selector
  nodeSelector: {}

  ## Affinity
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
          - matchExpressions:
              - key: node-role.kubernetes.io/control-plane
                operator: Exists
          - matchExpressions:
              - key: node-role.kubernetes.io/master
                operator: Exists

  ## Tolerations
  tolerations: 
    - key: node-role.kubernetes.io/master
      operator: Exists
      effect: "NoSchedule"
    - key: node-role.kubernetes.io/control-plane
      operator: Exists
      effect: "NoSchedule"

  rbac:
    create: true
    ## Ignored if rbac.create is true
    serviceAccountName: default

  resources:
    limits:
      cpu: 100m
      memory: 128Mi
    requests:
      cpu: 100m
      memory: 128Mi
  
nfs-subdir-external-provisioner:
  replicaCount: 3
  strategyType: Recreate

  image:
    repository: ccr.ccs.tencentyun.com/tdccimages/nfs-subdir-external-provisioner
    tag: v4.0.2
    pullPolicy: IfNotPresent
  imagePullSecrets: []

  nfs:
    server:
    path: /nfs-storage
    mountOptions:
    volumeName: nfs-subdir-external-provisioner-root
    # Reclaim policy for the main nfs volume
    reclaimPolicy: Retain

  # For creating the StorageClass automatically:
  storageClass:
    create: true

    # Set a provisioner name. If unset, a name will be generated.
    # provisionerName:

    # Set StorageClass as the default StorageClass
    # Ignored if storageClass.create is false
    defaultClass: false

    # Set a StorageClass name
    # Ignored if storageClass.create is false
    name: anywhere-sc

    # Allow volume to be expanded dynamically
    allowVolumeExpansion: true

    # Method used to reclaim an obsoleted volume
    reclaimPolicy: Delete

    # When set to false your PVs will not be archived by the provisioner upon deletion of the PVC.
    archiveOnDelete: true

    # If it exists and has 'delete' value, delete the directory. If it exists and has 'retain' value, save the directory.
    # Overrides archiveOnDelete.
    # Ignored if value not set.
    onDelete:

    # Specifies a template for creating a directory path via PVC metadata's such as labels, annotations, name or namespace.
    # Ignored if value not set.
    pathPattern:

    # Set access mode - ReadWriteOnce, ReadOnlyMany or ReadWriteMany
    accessModes: ReadWriteMany 

    # Storage class annotations
    annotations: {}

  leaderElection:
    # When set to false leader election will be disabled
    enabled: true

  ## For RBAC support:
  rbac:
    # Specifies whether RBAC resources should be created
    create: true

  # If true, create & use Pod Security Policy resources
  # https://kubernetes.io/docs/concepts/policy/pod-security-policy/
  podSecurityPolicy:
    enabled: false

  # Deployment pod annotations
  podAnnotations: {}

  ## Set pod priorityClassName
  # priorityClassName: ""

  podSecurityContext: {}

  securityContext: {}

  serviceAccount:
    # Specifies whether a ServiceAccount should be created
    create: true

    # Annotations to add to the service account
    annotations: {}

    # The name of the ServiceAccount to use.
    # If not set and create is true, a name is generated using the fullname template
    name:

  resources: {}
    # limits:
    #  cpu: 100m
    #  memory: 128Mi
    # requests:
    #  cpu: 100m
    #  memory: 128Mi

  nodeSelector: {}

  tolerations: 
    - key: node-role.kubernetes.io/master
      operator: Exists
      effect: "NoSchedule"
    - key: node-role.kubernetes.io/control-plane
      operator: Exists
      effect: "NoSchedule"

  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
          - matchExpressions:
              - key: node-role.kubernetes.io/control-plane
                operator: Exists
          - matchExpressions:
              - key: node-role.kubernetes.io/master
                operator: Exists

  # Additional labels for any resource created
  labels: {}

ceph-csi-cephfs:
  rbac:
    # Specifies whether RBAC resources should be created
    create: true

  serviceAccounts:
    nodeplugin:
      # Specifies whether a ServiceAccount should be created
      create: true
      # The name of the ServiceAccount to use.
      # If not set and create is true, a name is generated using the fullname
      name:
    provisioner:
      # Specifies whether a ServiceAccount should be created
      create: true
      # The name of the ServiceAccount to use.
      # If not set and create is true, a name is generated using the fullname
      name:

  # Configuration for the CSI to connect to the cluster
  # Ref: https://github.com/ceph/ceph-csi/blob/devel/examples/README.md
  # Example:
  # csiConfig:
  #   - clusterID: "<cluster-id>"
  #     monitors:
  #       - "<MONValue1>"
  #       - "<MONValue2>"
  #     cephFS:
  #       subvolumeGroup: "csi"
  csiConfig: []

  # Set logging level for csi containers.
  # Supported values from 0 to 5. 0 for general useful logs,
  # 5 for trace level verbosity.
  logLevel: 5

  nodeplugin:
    name: nodeplugin
    # if you are using ceph-fuse client set this value to OnDelete
    updateStrategy: RollingUpdate

    # set user created priorityclassName for csi plugin pods. default is
    # system-node-critical which is highest priority
    priorityClassName: system-node-critical

    httpMetrics:
      # Metrics only available for cephcsi/cephcsi => 1.2.0
      # Specifies whether http metrics should be exposed
      enabled: true
      # The port of the container to expose the metrics
      containerPort: 8081

      service:
        # Specifies whether a service should be created for the metrics
        enabled: true
        # The port to use for the service
        servicePort: 8080
        type: ClusterIP

        # Annotations for the service
        # Example:
        # annotations:
        #   prometheus.io/scrape: "true"
        #   prometheus.io/port: "9080"
        annotations: {}

        clusterIP: ""

        ## List of IP addresses at which the stats-exporter service is available
        ## Ref: https://kubernetes.io/docs/user-guide/services/#external-ips
        ##
        externalIPs: []

        loadBalancerIP: ""
        loadBalancerSourceRanges: []

    profiling:
      enabled: false

    registrar:
      image:
        repository: ccr.ccs.tencentyun.com/tdccimages/csi-node-driver-registrar
        tag: v2.4.0
        pullPolicy: IfNotPresent
      resources: {}

    plugin:
      image:
        repository: ccr.ccs.tencentyun.com/tdccimages/cephcsi
        tag: v3.6.0
        pullPolicy: IfNotPresent
      resources: {}

    nodeSelector: {}

    tolerations: 
      - key: node-role.kubernetes.io/master
        operator: Exists
        effect: "NoSchedule"
      - key: node-role.kubernetes.io/control-plane
        operator: Exists
        effect: "NoSchedule"

    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
            - matchExpressions:
                - key: node-role.kubernetes.io/control-plane
                  operator: Exists
            - matchExpressions:
                - key: node-role.kubernetes.io/master
                  operator: Exists

    # Set to true to enable Ceph Kernel clients
    # on kernel < 4.17 which support quotas
    # forcecephkernelclient: true

    # If true, create & use Pod Security Policy resources
    # https://kubernetes.io/docs/concepts/policy/pod-security-policy/
    podSecurityPolicy:
      enabled: false

  provisioner:
    name: provisioner
    replicaCount: 3
    strategy:
      # RollingUpdate strategy replaces old pods with new ones gradually,
      # without incurring downtime.
      type: RollingUpdate
      rollingUpdate:
        # maxUnavailable is the maximum number of pods that can be
        # unavailable during the update process.
        maxUnavailable: 50%
    # Timeout for waiting for creation or deletion of a volume
    timeout: 60s

    # set user created priorityclassName for csi provisioner pods. default is
    # system-cluster-critical which is less priority than system-node-critical
    priorityClassName: system-cluster-critical

    httpMetrics:
      # Metrics only available for cephcsi/cephcsi => 1.2.0
      # Specifies whether http metrics should be exposed
      enabled: true
      # The port of the container to expose the metrics
      containerPort: 8081

      service:
        # Specifies whether a service should be created for the metrics
        enabled: true
        # The port to use for the service
        servicePort: 8080
        type: ClusterIP

        # Annotations for the service
        # Example:
        # annotations:
        #   prometheus.io/scrape: "true"
        #   prometheus.io/port: "9080"
        annotations: {}

        clusterIP: ""

        ## List of IP addresses at which the stats-exporter service is available
        ## Ref: https://kubernetes.io/docs/user-guide/services/#external-ips
        ##
        externalIPs: []

        loadBalancerIP: ""
        loadBalancerSourceRanges: []

    profiling:
      enabled: false

    provisioner:
      image:
        repository: ccr.ccs.tencentyun.com/tdccimages/csi-provisioner
        tag: v3.1.0
        pullPolicy: IfNotPresent
      resources: {}

    attacher:
      name: attacher
      enabled: true
      image:
        repository: ccr.ccs.tencentyun.com/tdccimages/csi-attacher
        tag: v3.4.0
        pullPolicy: IfNotPresent
      resources: {}

    resizer:
      name: resizer
      enabled: true
      image:
        repository: ccr.ccs.tencentyun.com/tdccimages/csi-resizer
        tag: v1.4.0
        pullPolicy: IfNotPresent
      resources: {}

    snapshotter:
      image:
        repository: ccr.ccs.tencentyun.com/tdccimages/csi-snapshotter
        tag: v4.2.0
        pullPolicy: IfNotPresent
      resources: {}

    nodeSelector: {}

    tolerations: 
      - key: node-role.kubernetes.io/master
        operator: Exists
        effect: "NoSchedule"
      - key: node-role.kubernetes.io/control-plane
        operator: Exists
        effect: "NoSchedule"

    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
            - matchExpressions:
                - key: node-role.kubernetes.io/control-plane
                  operator: Exists
            - matchExpressions:
                - key: node-role.kubernetes.io/master
                  operator: Exists

    # If true, create & use Pod Security Policy resources
    # https://kubernetes.io/docs/concepts/policy/pod-security-policy/
    podSecurityPolicy:
      enabled: false

  # Mount the host /etc/selinux inside pods to support
  # selinux-enabled filesystems
  selinuxMount: true

  topology:
    # Specifies whether topology based provisioning support should
    # be exposed by CSI
    enabled: false
    # domainLabels define which node labels to use as domains
    # for CSI nodeplugins to advertise their domains
    # NOTE: the value here serves as an example and needs to be
    # updated with node labels that define domains of interest
    domainLabels:
      - failure-domain/region
      - failure-domain/zone

  storageClass:
    # Specifies whether the Storage class should be created
    create: true
    name: anywhere-sc
    # Annotations for the storage class
    # Example:
    # annotations:
    #   storageclass.kubernetes.io/is-default-class: "true"
    annotations: {}

    # String representing a Ceph cluster to provision storage from.
    # Should be unique across all Ceph clusters in use for provisioning,
    # cannot be greater than 36 bytes in length, and should remain immutable for
    # the lifetime of the StorageClass in use.
    clusterID: <cluster-ID>
    # (required) CephFS filesystem name into which the volume shall be created
    # eg: fsName: myfs
    fsName: myfs
    # (optional) Ceph pool into which volume data shall be stored
    # pool: <cephfs-data-pool>
    # For eg:
    # pool: "replicapool"
    pool: ""
    # (optional) Comma separated string of Ceph-fuse mount options.
    # For eg:
    # fuseMountOptions: debug
    fuseMountOptions: ""
    # (optional) Comma separated string of Cephfs kernel mount options.
    # Check man mount.ceph for mount options. For eg:
    # kernelMountOptions: readdir_max_bytes=1048576,norbytes
    kernelMountOptions: ""
    # (optional) The driver can use either ceph-fuse (fuse) or
    # ceph kernelclient (kernel).
    # If omitted, default volume mounter will be used - this is
    # determined by probing for ceph-fuse and mount.ceph
    # mounter: kernel
    mounter: fuse
    # (optional) Prefix to use for naming subvolumes.
    # If omitted, defaults to "csi-vol-".
    # volumeNamePrefix: "foo-bar-"
    volumeNamePrefix: ""
    # The secrets have to contain user and/or Ceph admin credentials.
    provisionerSecret: csi-cephfs-secret
    # If the Namespaces are not specified, the secrets are assumed to
    # be in the Release namespace.
    provisionerSecretNamespace: ""
    controllerExpandSecret: csi-cephfs-secret
    controllerExpandSecretNamespace: ""
    nodeStageSecret: csi-cephfs-secret
    nodeStageSecretNamespace: ""
    reclaimPolicy: Delete
    allowVolumeExpansion: true
    mountOptions: []
    # Mount Options
    # Example:
    # mountOptions:
    #   - discard

  secret:
    # Specifies whether the secret should be created
    create: true
    name: csi-cephfs-secret
    # Key values correspond to a user name and its key, as defined in the
    # ceph cluster. User ID should have required access to the 'pool'
    # specified in the storage class
    adminID: <plaintext ID>
    adminKey: <Ceph auth key corresponding to ID above>

  # This is a sample configmap that helps define a Ceph configuration as required
  # by the CSI plugins.
  # Sample ceph.conf available at
  # https://github.com/ceph/ceph/blob/master/src/sample.ceph.conf Detailed
  # documentation is available at
  # https://docs.ceph.com/en/latest/rados/configuration/ceph-conf/
  cephconf: |
    [global]
      auth_cluster_required = cephx
      auth_service_required = cephx
      auth_client_required = cephx

      # Workaround for http://tracker.ceph.com/issues/23446
      fuse_set_user_groups = false

      # ceph-fuse which uses libfuse2 by default has write buffer size of 2KiB
      # adding 'fuse_big_writes = true' option by default to override this limit
      # see https://github.com/ceph/ceph-csi/issues/1928
      fuse_big_writes = true

  #########################################################
  # Variables for 'internal' use please use with caution! #
  #########################################################

  # The filename of the provisioner socket
  provisionerSocketFile: csi-provisioner.sock
  # The filename of the plugin socket
  pluginSocketFile: csi.sock
  # kubelet working directory,can be set using `--root-dir` when starting kubelet.
  kubeletDir: /var/lib/kubelet
  # Name of the csi-driver
  driverName: cephfs.csi.ceph.com
  # Name of the configmap used for state
  configMapName: ceph-csi-config
  # Key to use in the Configmap if not config.json
  # configMapKey:
  # Use an externally provided configmap
  externallyManagedConfigmap: false
  # Name of the configmap used for ceph.conf
  cephConfConfigMapName: ceph-config
